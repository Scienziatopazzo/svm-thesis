{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis 5: Repeated Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import *\n",
    "from training import *\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal generated NA, max censoring, Standard scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = load_skl_dogs_2016(NApolicy='normal', censoringPolicy='max', scaler=StandardScaler())\n",
    "dogs.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with grid search model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'coef0': 100, 'degree': 3, 'epsilon': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "Test score: -0.016038\n",
      "Mean score of model on random test splits: -0.116339\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with grid search model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(5):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 1/8)\n",
    "    svreg = GridSearchCV(svm.SVR(), param_grid, cv=6, n_jobs=8)\n",
    "    svreg.fit(X_Train, y_Train)\n",
    "    curr_result = (svreg.best_params_, svreg.score(X_Test, y_Test))\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with repeated holdout model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 16, 'coef0': 100, 'degree': 2, 'epsilon': 0.0001, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Test score: 0.031020\n",
      "-0.09069422544979347\n",
      "Mean score of model on random test splits: -0.090694\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with repeated holdout model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': ['auto'], 'degree': [0], 'coef0':[0], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [0], 'coef0':[0], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    curr_result = SVR_gridsearch_holdout(X, y, svm.SVR, param_grid, 10, 15)\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal generated NA, drop censoring, Standard Scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = load_skl_dogs_2016(NApolicy='normal', censoringPolicy='drop', scaler=StandardScaler())\n",
    "dogs.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with grid search model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 16, 'coef0': 0, 'degree': 3, 'epsilon': 0.0001, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Test score: 0.066022\n",
      "Mean score of model on random test splits: -0.170716\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with grid search model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 1/8)\n",
    "    svreg = GridSearchCV(svm.SVR(), param_grid, cv=6, n_jobs=8)\n",
    "    svreg.fit(X_Train, y_Train)\n",
    "    curr_result = (svreg.best_params_, svreg.score(X_Test, y_Test))\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeated Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with repeated holdout model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 8, 'coef0': 100, 'degree': 3, 'epsilon': 0.0001, 'gamma': 0.0001, 'kernel': 'poly'}\n",
      "Test score: 0.279897\n",
      "-0.09315949440376499\n",
      "Mean score of model on random test splits: -0.093159\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with repeated holdout model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': ['auto'], 'degree': [0], 'coef0':[0], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [0], 'coef0':[0], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    curr_result = SVR_gridsearch_holdout(X, y, svm.SVR, param_grid, 10, 15)\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal generated NA, max censoring, QuantileTransformer scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 16)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = load_skl_dogs_2016(NApolicy='normal', censoringPolicy='max', scaler=QuantileTransformer())\n",
    "dogs.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with grid search model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 8, 'coef0': 0, 'degree': 2, 'epsilon': 10, 'gamma': 1, 'kernel': 'poly'}\n",
      "Test score: 0.140830\n",
      "Mean score of model on random test splits: -0.201410\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with grid search model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 1/8)\n",
    "    svreg = GridSearchCV(svm.SVR(), param_grid, cv=6, n_jobs=8)\n",
    "    svreg.fit(X_Train, y_Train)\n",
    "    curr_result = (svreg.best_params_, svreg.score(X_Test, y_Test))\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal generated NA, max censoring, outlier elimination, Standard scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = load_skl_dogs_2016(NApolicy='normal', censoringPolicy='max', scaler=StandardScaler(), outlier_detector=LocalOutlierFactor())\n",
    "dogs.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR with grid search model selection\n",
      "\n",
      "Best parameters set found on development set:\n",
      "{'C': 4, 'coef0': 100, 'degree': 3, 'epsilon': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "Test score: 0.058900\n",
      "Mean score of model on random test splits: -0.010849\n"
     ]
    }
   ],
   "source": [
    "print(\"SVR with grid search model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "\n",
    "param_grid = [\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'kernel': ['linear']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "  {'C': [0.5, 1, 2, 4, 8, 16], 'epsilon':[0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001], 'degree': [1,2,3], 'coef0': [0, 1, 10, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size = 1/8)\n",
    "    svreg = GridSearchCV(svm.SVR(), param_grid, cv=6, n_jobs=8)\n",
    "    svreg.fit(X_Train, y_Train)\n",
    "    curr_result = (svreg.best_params_, svreg.score(X_Test, y_Test))\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y, test_size=25)\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal generated NA, max censoring, Standard scaler (scaling only trainset)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs = load_skl_dogs_2016(NApolicy='normal', censoringPolicy='max', scaler=None)\n",
    "dogs.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"SVR with repeated holdout model selection\\n\")\n",
    "\n",
    "X, y = dogs.data, dogs.target\n",
    "param_grid = [\n",
    "    {'C': [1, 5, 10, 50, 100], 'epsilon':[0.1, 1, 10], 'gamma': [0.01, 0.001, 0.0001], 'degree': [2,3], 'coef0': [0, 1, 10, 50, 100], 'kernel': ['poly']}\n",
    " ]\n",
    "\n",
    "best_result = (0,-np.inf)\n",
    "\n",
    "for i in range(10):\n",
    "    curr_result = SVR_gridsearch_holdout(X, y, svm.SVR, param_grid, 10, 15, scaler=StandardScaler)\n",
    "    if curr_result[1] > best_result[1]:\n",
    "        best_result = curr_result\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(best_result[0])\n",
    "print(\"Test score: %f\" % best_result[1])\n",
    "\n",
    "mean_score = 0\n",
    "for i in range(10):\n",
    "    X_Scaler, y_Scaler = StandardScaler(), StandardScaler()\n",
    "    X_Train, X_Test, y_Train, y_Test = train_test_split(X, y.astype('float64'), test_size=25)\n",
    "    X_Scaler.fit(X_Train)\n",
    "    y_Scaler.fit(y_Train.reshape((-1,1)))\n",
    "    X_Train, y_Train = X_Scaler.transform(X_Train), y_Scaler.transform(y_Train.reshape((-1,1))).ravel()\n",
    "    X_Test, y_Test = X_Scaler.transform(X_Test), y_Scaler.transform(y_Test.reshape((-1,1))).ravel()\n",
    "    best_params = best_result[0]\n",
    "    best_svr = svm.SVR(**best_params)\n",
    "    best_svr.fit(X_Train, y_Train)\n",
    "    mean_score += best_svr.score(X_Test, y_Test)/10\n",
    "print(\"Mean score of model on random test splits: %f\" % mean_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
